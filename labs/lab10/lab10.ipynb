{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10: Sentiment Analysis for Beer Reviews (1/2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=400 src=\"sentiments.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment analysis is the extraction of sentiment, which is the positive or negative orientation that an author of a text expresses towards an object. Typically, sentiment analysis systems do the following:\n",
    "- Subjectivity classification: Is the text objective or subjective?\n",
    "- Polarity classification: Is the expressed opinion positive, neutral or negative? How positive, neutral or negative is the text?\n",
    "- Subject identification: Who/what is the target of the sentiment?\n",
    "\n",
    "Sentiment analysis is one of the key areas of text data science that has found widespread interest in various fields like [politics](https://www.aaai.org/ocs/index.php/ICWSM/ICWSM10/paper/viewFile/1441/1852) (voter sentiment), [business](https://www.forbes.com/sites/jiawertz/2018/11/30/why-sentiment-analysis-could-be-your-best-kept-marketing-secret/#11d682642bbe) (product opinion mining), and [finance](https://ieeexplore.ieee.org/document/7955659). These systems are either rule-based (with manually crafted rules) or machine learning based (to automatically learn relationships betweeen text and sentiment).\n",
    "\n",
    "In this lab we will use a dataset of beer reviews to motivate sentiment analysis of product reviews. We will manually build our own sentiment lexicon to analyze sentiment by inspecting some positive and negative reviews, and we will also try using a general purpose sentiment [lexicon](https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html#lexicon). Finally, we will try automatically building the sentiment lexicon using the `Counter` class as before.\n",
    "\n",
    "A good overview of sentiment analysis with useful links can be found [here](https://monkeylearn.com/sentiment-analysis/#sentiment-analysis-lexicons) or [here](https://www.sciencedirect.com/science/article/pii/S2090447914000550)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, load the usual modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "import re\n",
    "import gensim\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "logging.root.level = logging.CRITICAL \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "# direct plots to appear within the cell, and set their style\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we will use is of beer reviews. Each line of the dataset is a JSON object like so:\n",
    "\n",
    "```\n",
    "{\"beer_brewerId\": \"8481\", \"review_time\": \"1157587200\", \"review_overall\": \"13/20\", \"review_text\": \"On tap at the Springfield, PA location. Poured a deep and cloudy orange (almost a copper) color with a small sized off white head. Aromas or oranges and all around citric. Tastes of oranges, light caramel and a very light grapefruit finish. I too would not believe the 80+ IBUs - I found this one to have a very light bitterness with a medium sweetness to it. Light lacing left on the glass.\", \"review_aroma\": \"6/10\", \"review_appearance\": \"4/5\", \"review_profileName\": \"hopdog\", \"beer_style\": \"India Pale Ale &#40;IPA&#41;\", \"review_palate\": \"3/5\", \"review_taste\": \"6/10\", \"beer_name\": \"John Harvards Simcoe IPA\", \"beer_ABV\": \"5.4\", \"beer_beerId\": \"63836\"}\n",
    "```\n",
    "\n",
    "We will read and select 10000 of these objects (due to memory constraints)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file and build table\n",
    "filename = \"ratings.csv\"\n",
    "data = Table.read_table(filename)\n",
    "sample_size = data.num_rows\n",
    "data.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of a beer review is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.column('review_text')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the review scores are strings like `\"4/5\"`. We want to transform these into integers like `4` so that processing will be easier later. This can be done by using regex to match until the `'/'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform columns with scoring into ints\n",
    "review_cols = [\"review_appearance\", \"review_aroma\", \"review_overall\", \"review_palate\", \"review_taste\"]\n",
    "\n",
    "def transform_int(score):\n",
    "    return int(re.match(r'([0-9]*)\\/', score)[1])\n",
    "\n",
    "for col in review_cols:\n",
    "    review_score = data.apply(transform_int, col)\n",
    "    data = data.drop(col)\n",
    "    data = data.with_column(col, review_score)\n",
    "\n",
    "data.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the distribution of overall review scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist(\"review_overall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will classify reviews into three categories: positive, neutral and negative. To simplify matters, we will sort the reviews in increasing order of overall review score. The first third will be labelled negative, the next third neutral, and the last third positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by increasing review overall score\n",
    "data = data.sort(\"review_overall\")\n",
    "\n",
    "# label class\n",
    "c2i = {\"negative\": 1,\n",
    "       \"neutral\": 2,\n",
    "       \"positive\": 3}\n",
    "labels = [c2i[\"negative\"]] * int(sample_size/3)\n",
    "labels.extend([c2i[\"neutral\"]] * int(sample_size/3))\n",
    "labels.extend([c2i[\"positive\"]] * (int(sample_size/3)+1))\n",
    "\n",
    "# add to data\n",
    "data = data.with_column(\"class\", labels)\n",
    "data.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the subsequent sections, we will develop different models for scoring the sentiment of a beer review. To do so, we will split the dataset into a training set (80%) and a test set (20%). The training set will be used to develop the model, while the test set will be used to evaluate the model. This allows us to evaluate the model in a manner that is independent from how it was developed. \n",
    "\n",
    "We treat the problem of scoring the sentiment of beer review text as a two-step procedure:\n",
    "- Continuous score: Our models will output a sentiment score. We treat the provided overall review score (`scores_train`) as the gold standard metric of the review sentiment. The correlation of these two types of scores will indicate how well the model's predicted sentiment follows the actual sentiment.\n",
    "<p>\n",
    "- Discrete class: Using the predicted sentiment score, we will classify the reviews into negative, neutral and positive class. We treat the labelled actual classes as the gold standard class of the review. The accuracy of the predicted classes matching the actual classes also indicates model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "seed = 123\n",
    "\n",
    "train, test = train_test_split(data.to_df(), test_size=0.20, random_state=seed)\n",
    "train = Table.from_df(train)\n",
    "test = Table.from_df(test)\n",
    "\n",
    "x_train = train.column(\"review_text\")\n",
    "y_train = train.column(\"class\")\n",
    "scores_train = train.column(\"review_overall\")\n",
    "\n",
    "x_test = test.column(\"review_text\")\n",
    "y_test = test.column(\"class\")\n",
    "scores_test = test.column(\"review_overall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually Created Sentiment Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the rest of this lab, we will explore rule-based approaches to sentiment analysis. We are concerned with different ways of building a sentiment lexicon, which is a dictionary of positive and negative words.\n",
    "\n",
    "To manually construct this, we can explore a few of the reviews and pick out words that stand out as indicative of either negative or positive sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore negative reviews \n",
    "data_neg = train.where(\"class\", c2i[\"negative\"])\n",
    "samples_neg = data_neg.sample(k=3,  with_replacement=False)\n",
    "texts_neg = samples_neg.column(\"review_text\")\n",
    "scores_neg = samples_neg.column(\"review_overall\")\n",
    "\n",
    "print(\"Negative reviews\")\n",
    "for text, score in zip(texts_neg, scores_neg):\n",
    "    print(\"(%d): %s\" % (score, text), \"\\n\")\n",
    "    \n",
    "# explore neutral reviews \n",
    "data_neu = train.where(\"class\", c2i[\"neutral\"])\n",
    "samples_neu = data_neu.sample(k=3,  with_replacement=False)\n",
    "texts_neu = samples_neu.column(\"review_text\")\n",
    "scores_neu = samples_neu.column(\"review_overall\")\n",
    "\n",
    "print(\"Neutral reviews\")\n",
    "for text, score in zip(texts_neu, scores_neu):\n",
    "    print(\"(%d): %s\" % (score, text), \"\\n\")\n",
    "    \n",
    "# explore positive reviews \n",
    "data_pos = train.where(\"class\", c2i[\"positive\"])\n",
    "samples_pos = data_pos.sample(k=3,  with_replacement=False)\n",
    "texts_pos = samples_pos.column(\"review_text\")\n",
    "scores_pos = samples_pos.column(\"review_overall\")\n",
    "\n",
    "print(\"Positive reviews\")\n",
    "for text, score in zip(texts_pos, scores_pos):\n",
    "    print(\"(%d): %s\" % (score, text), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the words we identified from the samples of negative and positive reviews, we build the positive and negative sentiment lexicons as sets of words (effectively, vocabularies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build negative and positive lexicon     \n",
    "neg_lex = {\"bizarre\", \"rotten\", \"horrible\", \"bad\", \"terrible\", \n",
    "           \"bland\", \"unpleasant\", \"boring\", \"worse\", \"ew\", \n",
    "           \"disgusting\"}\n",
    "\n",
    "pos_lex = {\"sweet\", \"beautiful\",  \"wonderful\", \"smooth\", \"enjoyable\", \n",
    "           \"correct\", \"drinkable\", \"recommended\", \"good\", \"refreshing\",\n",
    "           \"incredible\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that in lab06 we relied on the following functions to process our text strings, removing any tokens with numerics, possessives, or empty strings. These functions also apply here in removing tokens that we do not want to consider in our scoring.\n",
    "\n",
    "Our scoring procedure is simply the following: +1 for a token in a positive lexicon, and -1 for a token in a negative lexicon. Then, a document has positive sentiment if its overall score is above 0, a negative sentiment if its overall score is below 0, and a neutral sentiment if its overall score is 0. This is a **bag of words** approach to sentiment analysis, where we treat each token in the review as an individual atomic unit. Can you think of problems with this approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple scoring function and auxiliary functions    \n",
    "def is_numeric(string):\n",
    "    return any(char.isdigit() for char in string)\n",
    "\n",
    "def has_poss_contr(string):\n",
    "    return '\\'s' in string\n",
    "\n",
    "def empty_string(string):\n",
    "    return not string\n",
    "\n",
    "def remove_string(string):\n",
    "    return is_numeric(string) or has_poss_contr(string) or empty_string(string)\n",
    "\n",
    "def score(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    tokens = text.lower().strip().split(' ')\n",
    "    tokens = [token for token in tokens if not remove_string(token)]\n",
    "\n",
    "    score = 0\n",
    "    for token in tokens:\n",
    "        if token in neg_lex:\n",
    "            score -= 1\n",
    "        elif token in pos_lex:\n",
    "            score += 1\n",
    "    return score\n",
    "\n",
    "def classify(score):\n",
    "    if score < 0:\n",
    "        return 1\n",
    "    elif score == 0:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the above sentiment lexicons and procedure described, we then score all beer reviews in the test set. Using the predicted scores, we also classify each beer review into a class of positive, neutral or negative sentiment.\n",
    "\n",
    "To evaluate the model, we compute the following:\n",
    "- Correlation coefficient: a numerical measure of the relationship between two variables. A higher value indicates a stronger correlation. To visualize this, we also plot a scatterplot.\n",
    "- Accuracy: the % accuracy of the model in predicting the class of a sentiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score test set\n",
    "pred_scores = [score(text) for text in x_test]\n",
    "pred_class = [classify(score) for score in pred_scores]\n",
    "\n",
    "# correlation (for scores), accuracy (for class)\n",
    "corr = np.corrcoef(scores_test, pred_scores)[0,1]\n",
    "acc = np.mean(np.equal(y_test, pred_class))\n",
    "print(\"Correlation coefficient: %f\" % corr)\n",
    "print(\"Classification accuracy: %f\" % acc)\n",
    "\n",
    "# scatterplot\n",
    "plt.scatter(scores_test, pred_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs only slightly better than chance (36.8% compared to 33.3%), and has a weak correlation coefficient. How can we do better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn!\n",
    "\n",
    "Using the procedure above, expand the negative and positive lexicons by manually adding in 5 words *each*, which correspond to a negative and positive sentiment respectively. \n",
    "\n",
    "To do so, you should sample negative, neutral and positive reviews as above, and then pick out words that you think uniquely represent the corresponding sentiment. Show your results in terms of correlation coefficieent and classification accuracy.\n",
    "\n",
    "How much improvement are you able to attain?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Purpose Sentiment Lexicon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of manually building our sentiment lexicon, we'll adopt a general purpose sentiment lexicon created by Hu and Liu. This lexicon was specifically [created](https://www.cs.uic.edu/~liub/publications/kdd04-revSummary.pdf) to handle customer reviews, so we expect performance of our model to increase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip opinion-lexicon-English.zip\n",
    "\n",
    "def load_lexicon(filename):\n",
    "    \"\"\"\n",
    "    Load a file from Bing Liu's sentiment lexicon\n",
    "    (https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html#lexicon), containing\n",
    "    English words in Latin-1 encoding.\n",
    "    \n",
    "    One file contains a list of positive words, and the other contains\n",
    "    a list of negative words. The files contain comment lines starting\n",
    "    with ';' and blank lines, which should be skipped.\n",
    "    \n",
    "    With thanks to Robyn Speer (http://blog.conceptnet.io/posts/2017/how-to-make-a-racist-ai-without-really-trying/)\n",
    "    \"\"\"\n",
    "    lexicon = []\n",
    "    with open(filename, encoding='latin-1') as infile:\n",
    "        for line in infile:\n",
    "            line = line.rstrip()\n",
    "            if line and not line.startswith(';'):\n",
    "                lexicon.append(line)\n",
    "    return lexicon\n",
    "\n",
    "pos_lex = set(load_lexicon('opinion-lexicon-English/positive-words.txt'))\n",
    "neg_lex = set(load_lexicon('opinion-lexicon-English/negative-words.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, evaluate this model built on the general purpose sentiment lexicon by calculating the correlation coefficieent and classification accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score test set\n",
    "pred_scores = [score(text) for text in x_test]\n",
    "pred_class = [classify(score) for score in pred_scores]\n",
    "\n",
    "# correlation (for scores), accuracy (for class)\n",
    "corr = np.corrcoef(scores_test, pred_scores)[0,1]\n",
    "acc = np.mean(np.equal(y_test, pred_class))\n",
    "print(\"Correlation coefficient: %f\" % corr)\n",
    "print(\"Classification accuracy: %f\" % acc)\n",
    "\n",
    "# scatterplot\n",
    "plt.scatter(scores_test, pred_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieve only slightly better correlation and classification accuracy. The lesson here is that sentiment lexicons created in a general purpose manner tend not to generalize well to domain specific datasets. Intuitively, beer reviews contain tokens that carry positive and negative sentiment specific to the domain of rating beer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatically Created Sentiment Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will automatically create our sentiment lexicons by building a pos/neg dictionary of words over the positive beer reviews and negative beer reviews respectively. Take note that we should only do this over the training set! **Why?** \n",
    "\n",
    "Using previous techniques (the `Counter` class), we can easily build this lexicon. Since the positive and negative lexicons are likely to contain many common words, we only want to count words that do not appear in both lexicons in the respective positive / negative lexicon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build negative lexicon\n",
    "texts_neg = train.where(\"class\", c2i[\"negative\"]).column(\"review_text\")\n",
    "vocab_neg = Counter()\n",
    "texts_neg_tok = [text.lower().strip().split(' ') for text in texts_neg]\n",
    "texts_neg_tok = [[token for token in text if not remove_string(token)] for text in texts_neg_tok]\n",
    "for text in texts_neg_tok:\n",
    "    vocab_neg.update(text)\n",
    "neg_lex = set(vocab_neg)\n",
    "\n",
    "# build positive lexicon\n",
    "texts_pos = train.where(\"class\", c2i[\"positive\"]).column(\"review_text\")\n",
    "vocab_pos = Counter()\n",
    "texts_pos_tok = [text.lower().strip().split(' ') for text in texts_pos]\n",
    "texts_pos_tok = [[token for token in text if not remove_string(token)] for text in texts_pos_tok]\n",
    "for text in texts_pos_tok:\n",
    "    vocab_pos.update(text)\n",
    "pos_lex = set(vocab_pos)\n",
    "\n",
    "intersect = neg_lex.intersection(pos_lex)\n",
    "neg_lex = neg_lex - intersect\n",
    "pos_lex = pos_lex - intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score test set\n",
    "pred_scores = [score(text) for text in x_test]\n",
    "pred_class = [classify(score) for score in pred_scores]\n",
    "\n",
    "# correlation (for scores), accuracy (for class)\n",
    "corr = np.corrcoef(scores_test, pred_scores)[0,1]\n",
    "acc = np.mean(np.equal(y_test, pred_class))\n",
    "print(\"Correlation coefficient: %f\" % corr)\n",
    "print(\"Classification accuracy: %f\" % acc)\n",
    "\n",
    "# scatterplot\n",
    "plt.scatter(scores_test, pred_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our performance is the best yet! This is not too surprising, since this method manages to capture the domain specific semantics for rating beer in a positive or negative manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn!\n",
    "\n",
    "Currently, we build both sentiment lexicons over the full training data. How does model performance change when we only use a smaller subset of the training data?\n",
    "\n",
    "Analyze how the performance of this model (automatically constructing the negative and positive lexicon) varies as you change the size of training set over which to build the lexicons. Make sure your size range is between 800 to 8000 inclusive! \n",
    "\n",
    "Discuss and suggest reasons for the observed trend.\n",
    "\n",
    "You can use the following to get started:\n",
    "\n",
    "```\n",
    "def build_lexicons(train, c2i, size):\n",
    "    \n",
    "    # sample train set\n",
    "    subset = train.sample(size, with_replacement=False)\n",
    "    \n",
    "    # build negative lexicon\n",
    "    \n",
    "    # build positive lexicon\n",
    "    \n",
    "    # return lexicons\n",
    "    \n",
    "# define step size and list of sizes to use\n",
    "\n",
    "# for each size\n",
    "\n",
    "    # build lexicons\n",
    "    \n",
    "    # obtain predicted scores and classes\n",
    "    \n",
    "    # compute correlation coefficient and accuracy\n",
    "    \n",
    "# plot the correlation and accuracy, against sizes, on same graph\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
